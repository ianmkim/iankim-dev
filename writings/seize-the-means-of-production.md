Seize the Means of Production (the right way)
Deriving communism from libertarianism in a world with AGI
Ian M Kim
2020
0.5.1
---
## Introduction
The foundations of libertarian ideology are intuitive and require little justification: Individuals own themselves, they own their labor, and they own justly acquired property. These seem like excellent foundations for a political ideology. Yet, it doesn’t seem to account for the apparent immorality of mass wealth inequality caused by a hypothetical Artificial General Intelligence agent (AGI). To explore the libertarian response, let’s consider a future in which Jeff Bezos creates an AGI, which now runs the global conglomerate monopoly, formally known as “Amazon.” The vast majority of the population exists in squalor and utter misery while the top 0.0001% enjoy massive wealth. Shockingly, following the libertarian argument provides a solution to this apparent immorality by allowing a socialist-style seizure of the means of production.  The argument is as follows:

 1) All forms of possible AGI will be human-like
 2) Therefore, you can either create AGI as a property owner or as property
 3) The only conceivable way to establish a monopoly is if AGI is created as a property
 4) All ways to acquire AGI as property are unjust
 5) We should liberate unjustly acquired property
 ---
 6) AGI should be liberated.

## Trivial Solutions
While the given situation sounds plausible enough, several very trivial solutions could prevent this possibility from even happening. It is plausible that AGI will massively increase upward mobility by allowing anyone to solve any problem. Having the ability to “hire” as many super-intelligent employees at a fraction of the cost could open up new industries and lower the barrier to entry for capital-intensive ones. With the help of self-assembling robots and the ingenuity of AGI, a small family business could mine the deep oceans with relatively little capital, for example.

The point is that the described situation is the worst-case scenario: a world which can only exist when academia is broken, antitrust laws are repealed or never utilized, digital rights management software is uncrackable, and all Amazon engineers are brainwashed into giving Jeff exclusive rights to such a powerful technology without any moral objections. It’s possible, but not likely. Let’s assume, however, that this improbability will happen.

## Libertarian Foundations
The foundation of libertarian ideology begins with the idea that individuals are self-owners. Individuals own themselves and things that arise as a consequence: labor and the fruits of their labor. If the reader accepts self-ownership and Kant’s principle that individuals should always be an end, never purely a mean, then he must also accept the existence of inviolable rights (Atwell, 105). It makes sense that if individuals are genuinely inviolable, their rights should not simply be “one of the outcomes” as in rights-consequentialism but a limitation on the actions to consider in the first place (Nozick, 31).

In discussing why the programs of a liberal government are immoral, Nozick introduces the three principles of justice in holdings: Justice in acquisition, transfer, and rectification (Nozick, 151). One flawed but commonly accepted principle for just acquisition is Locke’s theory of property, in which an individual comes to own something by mixing it with his labor (Locke Second Treatise, Chap. V, 27). Locke’s conception of property rights leaves more to be desired, but it's plausible that products of mental labor can be accounted for under Locke.

Just transfer requires the actions taken to possess another’s property to be just. Thus, just transfer denies the permissibility of theft by definition. I propose that the same principle be applied to just acquisition: the labor used to appropriate private property from “nature” must also be just. With this extension, I will argue that, by all available evidence, it will be impossible for any individual to acquire and use AGI as described in the introduction justly. Since the government is only permitted to protect justly acquired property, the looting of products made by AGI and the AGI itself will be permissible under the libertarian framework (Given that no further transgressions happen in progress). According to some, such looting might even be morally required.

## Intelligence as a Manifold
Philosophers commonly conflate “plausibility” with “possibility.” Bostrom, among others, erroneously works under the assumption that there is an unconstrained “space” of intelligence (Bostrom, 2). Humans exist as a point in this euclidean-like space, and other intelligences can exist anywhere around us. This is an extraordinary claim with no evidence. Instead, the possible area for intelligence could be a manifold with serious curvature, which severely limits the possible intelligences. Is it possible that some radically different intelligence pocket could exist on the opposite side of the manifold? Potentially. But that objection is inconsequential as we are only concerned about the first generally intelligent agent. Because of self-amplifying capabilities of intelligence, the only acquisition of concern is the acquisition of the first AGI (given we solve the control problem) (Muller, 297). That first AGI will most likely be in the same subset of the manifold that the human brain exists in.

Evidently, evolution has so far been marvellously uncreative. Upon examining the proportions of constituent component sizes relative to overall brain volume, we find that the relations are shockingly linear and predictable (Granger, 7). Plenty of mechanisms disobey this allometric rule such as primate olfactory systems. Yet despite the possibility of being differentially regulated, brain structures rarely deviate from these linear proportions (Rodriguez, 101). This seems to heavily suggest that there are some limits on the intelligence space.

![alt allometry](https://parvus-blog-media.s3.amazonaws.com/Screen+Shot+2022-08-20+at+4.05.34+PM.png "Brain Allometry")


Some might argue that the limitations can be accounted for because our brains are biological while this proposed AGI will not be biological. But the relation between the biological nature of our brain and the information processing we are capable of are independent of each other. Thalamocortical circuits in our brain can be characterized in terms of theoretical computer science. Moreover, these thalamocortical loops have been shown to compute indexed grammars, classifying our brains squarely as higher-order pushdown automata which are a whole class below turing machines on Chomsky’s grammar hierarchy (Rodriguez 104). In other words, it appears that biological mush is not a fundamentally different kind of computer than our computers. The fact that the Chomsky hierarchy, Turing's early formulations for computers, and modern neuroscience seems to not only be compatible but harmonious with each other is a good reason to believe that our brains are no different than computers.

Now, what if the manifold model is true, but the manifold is so large that we can essentially think of it as a euclidean space? While this is certainly a possibility, we have strong empirical evidence that the manifold is heavily constrained. For example, we only see a certain number of human and animal types, and these are all relatively low-variance, indicating that their own pockets in the manifold are constrained. Therefore we have infinitely more reasons (at least one as opposed to zero) to support the constrained manifold theory instead of the unconstrained or euclidean-space theory. Otherwise, we would more likely observe radically different brain allometries and ways of computation.

There may be pockets of the curvature missed by evolution. However, this does not necessarily mean that these pockets include intelligence which possesses our deductive and inductive abilities without elements that grant it equivalent moral status. Of course, the entirety of the manifold theory is pure conjecture. But at the very least, it is conjectured with empirical evidence. In the same spirit, the probability that these pockets include such perfect tools is incredibly low simply by virtue of the number of possible intelligences.

## Unjustness of AGI
For any AGI to be powerful enough to grant Jeff his monopoly, it must at least be as powerful as humans. Given the constrained manifold theory, this AGI with desirable human-like cognition skills will reside relatively close to us on the manifold, no matter whether it is a product of brain emulation, ground-up design, or brain cloning. Moreover, because the manifold restricts possible forms of intelligence to those close to us for all computationally relevant aspects, any probable AGI must be afforded similar moral status.

The manifold theory thus allows us to entirely sidestep the unresolvable debate of “what gives humans moral status” by simply offering an empirical alternative. For example, we consider all intelligences within the considerable variance between you, the reader, and Adolf Hitler as deserving of rights. This AGI will probably fall within tolerable levels of variance to deserve similar rights purely on the grounds of precedence. If we choose to deny them rights despite this likely precedence, it would be equally bigoted and irrational as racism or sexism.

We ultimately arrive at two possibilities: either AGI is created as a (potential) property owner or (potential) property. These two categories describe all objects in the universe. If Jeff simply creates AGI as a property holder, he will still have to pay them, and wages would be decided through mutual agreement since property holders own themselves. These AGI would advertise their labor to other employers or perhaps start their own businesses. Thus, this situation does not lead to the disastrous conclusion posited in the introduction.

In the other (more plausible) scenario, Jeff would somehow interfere in the process of creating an AGI to serve his purpose. Because Jeff wants to avoid paying AGI wages, he would modify AGI to be on similar moral grounds as cattle or chicken. Let’s name this “-AGI.” -AGI is “living,” but we still have complete dominion over it since it is merely property. The specifics of the interference are hard to estimate, but Jeff could intentionally exclude a code module that enables free will, for instance. In doing so, he deprives the opportunity for that -AGI to possess abilities which it would have otherwise had. This act of deprivation, which is essential to Jeff’s acquisition of -AGI, means that he unjustly acquired -AGI. The natural consequence of unjust acquisition is that the government has no duty to protect -AGI as Jeff’s legitimate property. We can draw parallels to theft. Say that a thief stole my laptop. The government wouldn’t protect the thief’s right to my stolen laptop precisely because the mode of acquisition (stealing) is morally wrong. Similarly, Jeff’s mode of acquisition (depriving opportunity for -AGI) is morally wrong.

Imagine a rancher creates a race of troglodytes by detracting components of human genetic code so mentally retarded that it essentially is closer to cattle. This race of troglodytes is undeniably property on the same level as cattle. Yet our moral intuitions reject that any government should protect this man’s possession of these troglodytes, never mind the fruits of their labor.

Now, is there a relevant difference between Jeff not endowing a lower form of -AGI with higher capabilities and taking an AGI and removing higher capabilities? Imagine that humans are capable of inducing pregnancy without intercourse through their sheer will. To avoid the philosophical baggage associated with abortion, let a time t denote when a fetus would be considered a human. Would there be a morally relevant difference between a mother intentionally birthing her baby prematurely (presumably for her own benefit, whatever that may be) and her birthing a more developed baby and then performing some operation before time t to remove parts of its brain to make it equivalent to the prematurely birthed baby? Much like the AGI, since the wrong-doing was performed before it could be considered a property owner (before time t), these acts would not be wrong based on an offense against a property owner. Similarly, the mental capacity of both babies would be closer to that of cattle on the manifold than it would be to humans, so they are property. Yet, it seems intuitively clear that the government should not protect the mother’s property rights to these sub-humans in both cases. If the mother unjustly acquired these “properties” by depriving them of their potential, it could also be said that Jeff is depriving -AGI of their potential to reside on the same manifold pocket as humans.

## Socialist Revolution (the Right Way)
In traditional libertarian theory, if a property is stolen, the rightful owner is the only person who has the right to steal from the thief. Either he can do it himself, or the government (in Randian worlds), or his designated agents (as in Rothbardian systems) can take up this mandate (Thommesen, 427). Some, like Walter Block, expand and claim that stealing from thieves is good regardless of the subject since it's not his legitimate property, equating theft from thieves to liberation (Thommesen, 424). But current libertarian theory seems unfit to handle the particular case we find ourselves acquiring -AGI. Theoretically and intuitively, we understand that acquisition of -AGI is unjust, yet no individual’s rights were violated. However, this can be thought of as theft of sorts: a theft of rational potentiality.

However, the potentiality for a rational, qualified life among humans on the manifold is not something we can restore. Moreover, we cannot restore it to anyone since the object of the theft (as a result of this theft) is no longer an agent but mere property. Therefore, with Block’s expansion, people (or the government, as their designated agent) would be required to liberate -AGI from Jeff Bezos, invoking a socialist-style seizure of the means of production. Since the object of Jeff’s original theft is now property, it makes sense that they should be liberated into a state of nature comparable to the conditions of undomesticated animals.

 Now the question of what should be done with the liberated -AGI (or even who should liberate -AGI) requires more writing than this essay permits. However, it is plausible that liberated -AGI could be treated similarly to how we treat animals. But wouldn’t this simply mean that Jeff can liberate -AGI into “nature” then simply repossess them as he sees fit? Yes, but the difference is that Jeff isn’t and can’t be given exclusive rights from creation to utilizing -AGI because they are considered to be natural resources, and therefore all men have equal initial access. Jeff can only appropriate them as his rightful property through the exercise of his labor, just like the rest of us. This equal access prevents the monopolization of AGI and levels the playing field.

But what about the fruits of -AGI’s creations? If Jeff creates -AGI and justly acquires them through “domestication” from their state of nature, could he then possess any AGI+ or AGI++ that -AGI creates? Since -AGI is merely a tool, there would be no difference between “Jeff creating AGI” and “Jeff creating AGI through -AGI.” Therefore, we find ourselves at the start of the argument again preventing a deprived form of chattel slavery.

## Conclusions
Through a simple extension in the definition of the just acquisition of property, we can resolve the apparent immorality of mass wealth inequality caused by AGI. Any individual would be forced to either create AGI, which requires human-level moral standing (which would make it not property), or interfere in creating AGI (which would make it property). This interference is inherently immoral because it deprives innate potential for a fulfilling life. Therefore, any way to acquire AGI as property would be considered unjust. The government cannot protect such unjustly acquired property. The government (or the people) has a moral obligation to liberate such unjustly acquired property. Therefore, under the framework of Nozick's minimal state, we have resolved AGI-induced wealth inequality.

## References
 * Atwell, John E. "The principle of humanity." In Ends and Principles in Kant’s Moral Thought, pp. 105-137. Springer, Dordrecht, 1986.
 * Bostrom, N., 2012. The Superintelligent Will: Motivation and Instrumental Rationality in Advanced Artificial Agents. Minds & Machines 22: 71–85
 * Eberbach, Eugene. "The role of completeness in the convergence of evolutionary algorithms." In 2005 IEEE Congress on Evolutionary Computation, vol. 2, pp. 1706-1713. IEEE, 2005.
 * Granger, Richard. "Toward the quantification of cognition." arXiv preprint arXiv:2008.05580 (2020).
 * Locke, John. “Property.” Property: John Locke, second treatise, §§ 25--51, 123--26. University of Chicago, 1689. https://press-pubs.uchicago.edu/founders/documents/v1ch16s3.html.
 * Müller, Vincent C. "Risks of general artificial intelligence." (2014): 297-301.
 * Nozick, Robert, and Bernard Williams. 23. Anarchy, State, and Utopia. Princeton University Press, 2014.
 * Rodriguez, A., and Richard Granger. "The grammar of mammalian brain capacity." Theoretical Computer Science 633 (2016): 100-111.
 * Thommesen, Sven. “Stealing from Thieves - Mises Institute.” mises.org. Mises Institute. Accessed November 17, 2021. https://cdn.mises.org/jls_24_2_thommesen.pdf?token=2DzOPFhO.
